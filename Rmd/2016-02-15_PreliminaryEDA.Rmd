---
title: "Exploratory Data Analysis on SF Crime Data"
author: "M. Demas"
date: "15 February 2016"
output: pdf_document
---


```{r import-data}
train <- read.csv("~/Box Sync/KaggleSFCrime/Data/train.csv")
```

# Days of the Week
```{r relevel-day-factor}
train$DayOfWeek <- as.character(train$DayOfWeek)
train$DayOfWeek <- factor(train$DayOfWeek, levels=c("Sunday", "Monday", 
                                                    "Tuesday", "Wednesday", 
                                                    "Thursday", "Friday", 
                                                    "Saturday"))
```

```{r summarize-data-into-count}

```

# District Categorization
Crimes of day of the week is not very enlightening. So I conditioned it by District. This view shows that certain districts have greater number of incidents (e.g. Southern). Based on this plot it is clear that count varies with District (location). Another plot depicting the same information with color-coded categories has potential, but there are too many categories for the plot to be useful at this point. Thus, either using single plots based on the Category or by District may be more revealing. Additionally, as RD mentioned, 90% of the crimes are contained within 40 categories (crime count between 880 and 60022).
```{r plot-conditioned-on-district}
library(dplyr)
df <- train %>% 
  group_by(PdDistrict, DayOfWeek, Category) %>% 
  summarise(Count = n()) %>%
  arrange(Count)

fig_dir = '~/Box Sync/KaggleSFCrime/Figures/'
setwd(fig_dir)

library(ggplot2)
ggplot(df, aes(x=DayOfWeek, y=Count)) + geom_bar(stat="identity")
ggplot(df, aes(x=DayOfWeek, y=Count)) + 
  geom_bar(stat="identity") + 
  facet_wrap(~PdDistrict) +
  ggtitle("Count of Crimes for Each Day of the Week Conditioned on District")
ggsave('CrimeCountPerDayOfWeekInEachDistrict_2016-02-16.png')

ggplot(df, aes(x=DayOfWeek, y=Count, fill=Category)) + 
  geom_bar(stat="identity") + 
  facet_wrap(~PdDistrict, ncol=2) +
  ggtitle("Count of Crimes for Each Day of the Week Conditioned on District and Category") +
  theme(legend.position="bottom")
ggsave('CrimeCountPerDayOfWeekInEachDistrictColorByCategory_2016-02-16.png')
```

It would be helpful to filter out some of the unhelpful codes (such as "OTHER OFFENSES" and "SECONDARY CODES").
```{r excluding-lower-frequency-crimes}
tbl_df(df %>% arrange(desc(Count)))

ggplot(df %>% filter(Category != 'OTHER OFFENSES', Category != 'SECONDARY CODES'), aes(x=DayOfWeek, y=Count, fill=Category)) + 
  geom_bar(stat="identity") + 
  facet_wrap(~PdDistrict, ncol=2) +
  ggtitle("Count of Crimes for Each Day of the Week Conditioned on District and Category\n Top 40 Crimes") +
  theme(legend.position="bottom")
ggsave('CrimeCountPerDayOfWeekInEachDistrictColorByTopCategory_2016-02-16.png')



ggplot(df %>% filter(Count > 880, Category != 'OTHER OFFENSES'), aes(x=DayOfWeek, y=Count, fill=Category)) + 
  geom_bar(stat="identity") + 
  facet_wrap(~PdDistrict, ncol=2) +
  ggtitle("Count of Crimes for Each Day of the Week Conditioned on District and Category\n Top 40 Crimes") +
  theme(legend.position="bottom")
ggsave('CrimeCountPerDayOfWeekInEachDistrictColorByTopCategory_2016-02-16.png')
```


# Spatial Distribution
It would be interesting to understand how well SF is "mapped" by the crimes. A first scatter plot reveals some outliers Southern with coordinates long = -120.5, lat = 90 (perhaps they represent crimes across the bay?). I filtered out those values, and plotted again. The level of coverage seems fairly comprehensive. However, there appear to be some District misclassifications.
```{r scatter-plot-coordinates}

ggplot(train, aes(x=X, y=Y, color=PdDistrict)) + 
  geom_point(position='jitter') +
  ggtitle("Scatter Plot of Crimes (long.,lat.) Conditioned on District")
ggsave('CrimeScatterPlotInEachDistrict_2016-02-16.png')

ggplot(train %>% filter(X < -122.0, Y < 50), aes(x=X, y=Y, color=PdDistrict)) + 
  geom_point(position='jitter') +
  ggtitle("Scatter Plot of Crimes (long.,lat.) Conditioned on District")
ggsave('CrimeScatterPlotInEachDistrict_2016-02-16.png')

```


# Crimes with Low Counts
Filter out the low values. What should be the cutoff? Crimes with counts less than some value add noise to the data. Log-linear type analyses require certain cell counts in order to ensure interpretability. From a visual perspective, the frequency of crime counts per day of the week per district seem to stabilize between 50 and 100.
```{r crimes-with-low-counts}
ggplot(df, aes(x=Count)) +
  geom_density() +
  ggtitle('Density Plot of Number of Crimes Per District Per Day of the Week')
```

```{r crimes-with-counts-lt1000}
ggplot(df %>% filter(Count < 1000), aes(x=Count)) +
  geom_histogram(binwidth = 1) +
  ggtitle('Histogram of Number of Crimes Per District Per Day of the Week 
          (< 1000)')
```

```{r crimes-with-counts-lt250}
ggplot(df %>% filter(Count < 250), aes(x=Count)) +
  geom_histogram(binwidth = 2) +
  ggtitle('Histogram of Number of Crimes Per District Per Day of the Week
          (< 250)')
```

```{r crimes-with-counts-lt100}
ggplot(df %>% filter(Count < 100), aes(x=Count)) +
  geom_histogram(binwidth = 1) +
  ggtitle('Histogram of Number of Crimes Per District Per Day of the Week
          (< 100)')
```

## CDF of Crime Count Per District Per Day of the Week
Compute the CDF.
```{r crime-count-cdf}
df2 <- df %>% 
  dplyr::ungroup() %>% 
  select(PdDistrict, Category,Count) %>% 
  arrange(Count) %>% 
  mutate(CumSum = cumsum(Count)) %>%
  mutate(CDF = CumSum/max(CumSum))
```

```{r crime-count-cdf-plot}
ggplot(df2, aes(x=Count, y=CDF)) + 
  geom_point() + 
  ggtitle('Cumulative Density Function for Crime Count Frequency
Crime Per Day of the Week Per District')
```

```{r crime-count-cdf-plot-cdf-gt-75pct}
ggplot(df2 %>% filter(CDF > 0.75), 
       aes(x=Count, y=CDF, label = Category, color=Category)) + 
  geom_point() + 
  geom_text(angle = 90, nudge_y = -0.05) +
  ggtitle('Cumulative Density Function for Crime Count Frequency
Crime Per Day of the Week Per District')
```

```{r crime-count-cdf-district-wise}
df4 <- train %>% 
  group_by(PdDistrict, Category) %>% 
  summarise(Count = n()) %>%
  arrange(Count) %>% 
  mutate(CumSum = cumsum(Count))
```

```{r crime-count-cdf-plot-gt-75pct-by-district}
ggplot(df4 %>% filter(Count > 1000), 
       aes(x=log(Count), y=log(CumSum), label = Category, color=Category)) + 
  geom_point() + 
  # geom_text(angle = 315, nudge_y = 0.01, nudge_x = 0.01) +
  geom_text() +
  facet_wrap(~PdDistrict) +
  ggtitle('Cumulative Density Function for Crime Count Frequency
Crime Per District')
```

log-log plot is "linear"
```{r crime-count-cdf-plot-gt-75pct-by-district}
ggplot(df4, 
       aes(x=log(Count), y=log(CumSum), label = Category, color=Category)) + 
  geom_point() + 
  geom_text(angle = 315, nudge_y = 2, nudge_x = 5) +
  facet_wrap(~PdDistrict) +
  ggtitle('Cumulative Density Function for Crime Count Frequency
Crime Per District')
```

```{r all-crimes-cdf}
df3 <- train %>% 
  group_by(Category) %>% 
  summarise(Count = n()) %>%
  arrange(Count) %>% 
  mutate(CumSum = cumsum(Count)) %>%
  mutate(CDF = CumSum/max(CumSum))
```

```{r plot-cdf-all-crime}
ggplot(df3, aes(x=Count, y=CumSum, label=Category)) + 
  geom_point() + 
  geom_line() + 
  geom_text(check_overlap = TRUE) +
  ggtitle('Cumulative Density Function for Crime Count Frequency')

```

```{r plot-cdf-log-all-crime}
ggplot(df3, aes(x=log(Count), y=CDF, label=Category)) + 
  geom_point() + 
  geom_line() + 
  geom_text(angle=90, nudge_y = 0.05) +
  ggtitle('Cumulative Density Function for Crime Count Frequency')

```


# Crime Categorization Based on Criteria
I want the data to look like:

Criteria       | Category 1    | Category 2  | Marginal Total
-------------- | ------------- | ----------- | -----------
Categorization | 0.9           | 0.3         | sum to 1 ?
               | Total Count   |             |  

Minimize Error in Classification
Minimize difference between predicted probabilities and actual probabilities



# Questions
1. How does temporal resolution affect classification?
2. Do low counts have any relationship to time or space (District)?
3. What clusters of the data exist in time? (Hierarchical Clustering)

# Removing Data
1. Low counts
2. Misclassified crimes (spatially)
3. 
